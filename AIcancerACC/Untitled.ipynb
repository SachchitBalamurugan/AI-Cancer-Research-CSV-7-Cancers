{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aed84232-4208-4579-b859-b2a694f96984",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7727343716107761\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.59      0.71    108759\n",
      "           1       0.72      0.94      0.81    121751\n",
      "\n",
      "    accuracy                           0.77    230510\n",
      "   macro avg       0.81      0.76      0.76    230510\n",
      "weighted avg       0.80      0.77      0.76    230510\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/balam/Documents/AIcancerACC/prepared_dataset.csv')\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data = data.drop(columns=['Unnamed: 9', 'Unnamed: 10'])\n",
    "\n",
    "# Handle categorical data (if necessary)\n",
    "data['gene_type'] = LabelEncoder().fit_transform(data['gene_type'])\n",
    "\n",
    "# Define features and target\n",
    "X = data[['unstranded', 'stranded_first', 'stranded_second', \n",
    "          'tpm_unstranded', 'fpkm_unstranded', 'fpkm_uq_unstranded']]\n",
    "y = data['label']\n",
    "\n",
    "# Impute missing values in X\n",
    "imputer = SimpleImputer(strategy='mean')  # Replace 'mean' with 'median' or 'most_frequent' if appropriate\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Build the Random Forest Classifier\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae65c25b-8be2-47d5-8fc6-46121e3e7b85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23051/23051 [==============================] - 64s 3ms/step - loss: 0.6870 - accuracy: 0.5465 - val_loss: 0.6842 - val_accuracy: 0.5504\n",
      "Epoch 2/50\n",
      "23051/23051 [==============================] - 60s 3ms/step - loss: 0.6840 - accuracy: 0.5512 - val_loss: 0.6830 - val_accuracy: 0.5524\n",
      "Epoch 3/50\n",
      "23051/23051 [==============================] - 64s 3ms/step - loss: 0.6829 - accuracy: 0.5529 - val_loss: 0.6805 - val_accuracy: 0.5559\n",
      "Epoch 4/50\n",
      "23051/23051 [==============================] - 60s 3ms/step - loss: 0.6786 - accuracy: 0.5565 - val_loss: 0.6703 - val_accuracy: 0.5658\n",
      "Epoch 5/50\n",
      "23051/23051 [==============================] - 62s 3ms/step - loss: 0.6719 - accuracy: 0.5614 - val_loss: 0.6643 - val_accuracy: 0.5693\n",
      "Epoch 6/50\n",
      "23051/23051 [==============================] - 65s 3ms/step - loss: 0.6682 - accuracy: 0.5644 - val_loss: 0.6614 - val_accuracy: 0.5697\n",
      "Epoch 7/50\n",
      "23051/23051 [==============================] - 62s 3ms/step - loss: 0.6652 - accuracy: 0.5674 - val_loss: 0.6539 - val_accuracy: 0.5786\n",
      "Epoch 8/50\n",
      "23051/23051 [==============================] - 65s 3ms/step - loss: 0.6615 - accuracy: 0.5721 - val_loss: 0.6550 - val_accuracy: 0.5784\n",
      "Epoch 9/50\n",
      "23051/23051 [==============================] - 63s 3ms/step - loss: 0.6577 - accuracy: 0.5748 - val_loss: 0.6425 - val_accuracy: 0.5856\n",
      "Epoch 10/50\n",
      "23051/23051 [==============================] - 63s 3ms/step - loss: 0.6558 - accuracy: 0.5753 - val_loss: 0.6527 - val_accuracy: 0.5737\n",
      "Epoch 11/50\n",
      "23051/23051 [==============================] - 60s 3ms/step - loss: 0.6574 - accuracy: 0.5718 - val_loss: 0.6435 - val_accuracy: 0.5818\n",
      "Epoch 12/50\n",
      "23051/23051 [==============================] - 60s 3ms/step - loss: 0.6515 - accuracy: 0.5781 - val_loss: 0.6418 - val_accuracy: 0.5798\n",
      "Epoch 13/50\n",
      "23051/23051 [==============================] - 64s 3ms/step - loss: 0.6524 - accuracy: 0.5772 - val_loss: 0.6480 - val_accuracy: 0.5754\n",
      "Epoch 14/50\n",
      "23051/23051 [==============================] - 65s 3ms/step - loss: 0.6511 - accuracy: 0.5769 - val_loss: 0.6410 - val_accuracy: 0.5787\n",
      "Epoch 15/50\n",
      "23051/23051 [==============================] - 65s 3ms/step - loss: 0.6515 - accuracy: 0.5759 - val_loss: 0.6329 - val_accuracy: 0.5857\n",
      "Epoch 16/50\n",
      "23051/23051 [==============================] - 68s 3ms/step - loss: 0.6505 - accuracy: 0.5782 - val_loss: 0.6298 - val_accuracy: 0.5874\n",
      "Epoch 17/50\n",
      "23051/23051 [==============================] - 58s 3ms/step - loss: 0.6448 - accuracy: 0.5807 - val_loss: 0.6326 - val_accuracy: 0.5912\n",
      "Epoch 18/50\n",
      "23051/23051 [==============================] - 61s 3ms/step - loss: 0.6464 - accuracy: 0.5792 - val_loss: 0.6333 - val_accuracy: 0.6119\n",
      "Epoch 19/50\n",
      "23051/23051 [==============================] - 64s 3ms/step - loss: 0.6461 - accuracy: 0.5797 - val_loss: 0.6280 - val_accuracy: 0.5905\n",
      "Epoch 20/50\n",
      "23051/23051 [==============================] - 63s 3ms/step - loss: 0.6426 - accuracy: 0.5808 - val_loss: 0.6183 - val_accuracy: 0.5955\n",
      "Epoch 21/50\n",
      "23051/23051 [==============================] - 62s 3ms/step - loss: 0.6454 - accuracy: 0.5804 - val_loss: 0.6228 - val_accuracy: 0.5917\n",
      "Epoch 22/50\n",
      "23051/23051 [==============================] - 64s 3ms/step - loss: 0.6422 - accuracy: 0.5822 - val_loss: 0.6102 - val_accuracy: 0.6075\n",
      "Epoch 23/50\n",
      "23051/23051 [==============================] - 64s 3ms/step - loss: 0.6451 - accuracy: 0.5795 - val_loss: 0.6341 - val_accuracy: 0.5845\n",
      "Epoch 24/50\n",
      "23051/23051 [==============================] - 64s 3ms/step - loss: 0.6435 - accuracy: 0.5801 - val_loss: 0.6429 - val_accuracy: 0.5903\n",
      "Epoch 25/50\n",
      "23051/23051 [==============================] - 64s 3ms/step - loss: 0.6444 - accuracy: 0.5804 - val_loss: 0.6249 - val_accuracy: 0.6000\n",
      "Epoch 26/50\n",
      "23051/23051 [==============================] - 65s 3ms/step - loss: 0.6414 - accuracy: 0.5823 - val_loss: 0.6299 - val_accuracy: 0.5940\n",
      "Epoch 27/50\n",
      "23051/23051 [==============================] - 64s 3ms/step - loss: 0.6399 - accuracy: 0.5832 - val_loss: 0.6073 - val_accuracy: 0.6083\n",
      "Epoch 28/50\n",
      "23051/23051 [==============================] - 64s 3ms/step - loss: 0.6401 - accuracy: 0.5834 - val_loss: 0.6153 - val_accuracy: 0.6054\n",
      "Epoch 29/50\n",
      "23051/23051 [==============================] - 64s 3ms/step - loss: 0.6469 - accuracy: 0.5777 - val_loss: 0.6243 - val_accuracy: 0.5967\n",
      "Epoch 30/50\n",
      "23051/23051 [==============================] - 65s 3ms/step - loss: 0.6448 - accuracy: 0.5800 - val_loss: 0.6246 - val_accuracy: 0.5965\n",
      "Epoch 31/50\n",
      "23051/23051 [==============================] - 63s 3ms/step - loss: 0.6407 - accuracy: 0.5814 - val_loss: 0.6227 - val_accuracy: 0.5901\n",
      "Epoch 32/50\n",
      "23051/23051 [==============================] - 73s 3ms/step - loss: 0.6400 - accuracy: 0.5815 - val_loss: 0.6376 - val_accuracy: 0.5872\n",
      "Epoch 33/50\n",
      "23051/23051 [==============================] - 72s 3ms/step - loss: 0.6407 - accuracy: 0.5824 - val_loss: 0.6260 - val_accuracy: 0.5919\n",
      "Epoch 34/50\n",
      "23051/23051 [==============================] - 76s 3ms/step - loss: 0.6382 - accuracy: 0.5838 - val_loss: 0.6414 - val_accuracy: 0.5818\n",
      "Epoch 35/50\n",
      "23051/23051 [==============================] - 74s 3ms/step - loss: 0.6461 - accuracy: 0.5834 - val_loss: 0.6461 - val_accuracy: 0.5746\n",
      "Epoch 36/50\n",
      "23051/23051 [==============================] - 68s 3ms/step - loss: 0.6407 - accuracy: 0.5804 - val_loss: 0.6292 - val_accuracy: 0.5466\n",
      "Epoch 37/50\n",
      "23051/23051 [==============================] - 77s 3ms/step - loss: 0.6433 - accuracy: 0.5800 - val_loss: 0.6328 - val_accuracy: 0.5914\n",
      "Epoch 38/50\n",
      "23051/23051 [==============================] - 77s 3ms/step - loss: 0.6411 - accuracy: 0.5802 - val_loss: 0.6242 - val_accuracy: 0.5989\n",
      "Epoch 39/50\n",
      "23051/23051 [==============================] - 78s 3ms/step - loss: 0.6433 - accuracy: 0.5801 - val_loss: 0.6312 - val_accuracy: 0.5941\n",
      "Epoch 40/50\n",
      "23051/23051 [==============================] - 77s 3ms/step - loss: 0.6407 - accuracy: 0.5816 - val_loss: 0.6235 - val_accuracy: 0.5919\n",
      "Epoch 41/50\n",
      "23051/23051 [==============================] - 74s 3ms/step - loss: 0.6402 - accuracy: 0.5823 - val_loss: 0.6251 - val_accuracy: 0.6052\n",
      "Epoch 42/50\n",
      "23051/23051 [==============================] - 74s 3ms/step - loss: 0.6378 - accuracy: 0.5838 - val_loss: 0.6093 - val_accuracy: 0.6057\n",
      "Epoch 43/50\n",
      "23051/23051 [==============================] - 74s 3ms/step - loss: 0.6343 - accuracy: 0.5857 - val_loss: 0.6070 - val_accuracy: 0.6081\n",
      "Epoch 44/50\n",
      "23051/23051 [==============================] - 71s 3ms/step - loss: 0.6380 - accuracy: 0.5844 - val_loss: 0.6312 - val_accuracy: 0.5849\n",
      "Epoch 45/50\n",
      "23051/23051 [==============================] - 73s 3ms/step - loss: 0.6402 - accuracy: 0.5821 - val_loss: 0.6239 - val_accuracy: 0.5970\n",
      "Epoch 46/50\n",
      "23051/23051 [==============================] - 77s 3ms/step - loss: 0.6371 - accuracy: 0.5834 - val_loss: 0.6327 - val_accuracy: 0.5685\n",
      "Epoch 47/50\n",
      "23051/23051 [==============================] - 76s 3ms/step - loss: 0.6396 - accuracy: 0.5827 - val_loss: 0.6089 - val_accuracy: 0.6070\n",
      "Epoch 48/50\n",
      "23051/23051 [==============================] - 76s 3ms/step - loss: 0.6368 - accuracy: 0.5834 - val_loss: 0.6084 - val_accuracy: 0.6024\n",
      "Epoch 49/50\n",
      "23051/23051 [==============================] - 77s 3ms/step - loss: 0.6345 - accuracy: 0.5839 - val_loss: 0.6131 - val_accuracy: 0.5987\n",
      "Epoch 50/50\n",
      "23051/23051 [==============================] - 78s 3ms/step - loss: 0.6375 - accuracy: 0.5829 - val_loss: 0.6252 - val_accuracy: 0.5736\n",
      "7204/7204 [==============================] - 15s 2ms/step - loss: 0.6259 - accuracy: 0.5713\n",
      "Test Accuracy: 0.5712680816650391\n",
      "7204/7204 [==============================] - 19s 3ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.81      0.64    108759\n",
      "           1       0.68      0.36      0.47    121751\n",
      "\n",
      "    accuracy                           0.57    230510\n",
      "   macro avg       0.60      0.58      0.56    230510\n",
      "weighted avg       0.61      0.57      0.55    230510\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/balam/Documents/AIcancerACC/prepared_dataset.csv')\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data = data.drop(columns=['Unnamed: 9', 'Unnamed: 10'])\n",
    "\n",
    "# Handle categorical data (if necessary)\n",
    "data['gene_type'] = LabelEncoder().fit_transform(data['gene_type'])\n",
    "\n",
    "# Define features and target\n",
    "X = data[['unstranded', 'stranded_first', 'stranded_second', \n",
    "          'tpm_unstranded', 'fpkm_unstranded', 'fpkm_uq_unstranded']]\n",
    "y = data['label']\n",
    "\n",
    "# Impute missing values in X\n",
    "imputer = SimpleImputer(strategy='mean')  # Replace 'mean' with 'median' or 'most_frequent' if appropriate\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Encode the target variable if it has multiple classes\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "y = to_categorical(y)  # Convert to one-hot encoding for neural networks\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Build the Neural Network model\n",
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='relu'),  # Input layer\n",
    "    Dropout(0.2),  # Dropout to prevent overfitting\n",
    "    Dense(32, activation='relu'),  # Hidden layer\n",
    "    Dropout(0.2),\n",
    "    Dense(y_train.shape[1], activation='softmax')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = y_pred.argmax(axis=1)  # Convert probabilities to class labels\n",
    "y_test_classes = y_test.argmax(axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_classes, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b9fc13-92c5-4017-a790-8d7304c250a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balam\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "[I 2025-01-09 20:44:14,870] A new study created in memory with name: no-name-2c08b6d5-2b37-49b1-a189-abacf56172ba\n",
      "[I 2025-01-09 21:16:41,553] Trial 0 finished with value: 0.7230922736540714 and parameters: {'n_estimators': 263, 'max_depth': 17, 'min_samples_split': 10, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 0 with value: 0.7230922736540714.\n",
      "[I 2025-01-09 21:19:42,449] Trial 1 finished with value: 0.5897748470782178 and parameters: {'n_estimators': 103, 'max_depth': 9, 'min_samples_split': 19, 'min_samples_leaf': 8, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.7230922736540714.\n",
      "[I 2025-01-09 21:25:39,634] Trial 2 finished with value: 0.715821439416945 and parameters: {'n_estimators': 111, 'max_depth': 24, 'min_samples_split': 8, 'min_samples_leaf': 8, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.7230922736540714.\n",
      "[I 2025-01-09 21:49:14,377] Trial 3 finished with value: 0.7272179081167846 and parameters: {'n_estimators': 265, 'max_depth': 29, 'min_samples_split': 6, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 3 with value: 0.7272179081167846.\n",
      "[I 2025-01-09 21:52:14,624] Trial 4 finished with value: 0.7022515292178213 and parameters: {'n_estimators': 65, 'max_depth': 21, 'min_samples_split': 7, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 3 with value: 0.7272179081167846.\n",
      "[I 2025-01-09 22:05:38,719] Trial 5 finished with value: 0.7452952149581363 and parameters: {'n_estimators': 263, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 5 with value: 0.7452952149581363.\n",
      "[I 2025-01-09 22:19:07,109] Trial 6 finished with value: 0.7462669732332654 and parameters: {'n_estimators': 269, 'max_depth': 30, 'min_samples_split': 14, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 6 with value: 0.7462669732332654.\n",
      "[I 2025-01-09 22:55:11,824] Trial 7 finished with value: 0.7200425144245369 and parameters: {'n_estimators': 170, 'max_depth': 17, 'min_samples_split': 19, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 6 with value: 0.7462669732332654.\n",
      "[I 2025-01-09 23:12:51,369] Trial 8 finished with value: 0.590104550778708 and parameters: {'n_estimators': 257, 'max_depth': 9, 'min_samples_split': 20, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 6 with value: 0.7462669732332654.\n",
      "[I 2025-01-09 23:21:42,918] Trial 9 finished with value: 0.7081297991410351 and parameters: {'n_estimators': 96, 'max_depth': 16, 'min_samples_split': 10, 'min_samples_leaf': 6, 'max_features': None}. Best is trial 6 with value: 0.7462669732332654.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import optuna\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/balam/Documents/AIcancerACC/prepared_dataset.csv')\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data = data.drop(columns=['Unnamed: 9', 'Unnamed: 10'])\n",
    "\n",
    "# Handle categorical data (if necessary)\n",
    "data['gene_type'] = LabelEncoder().fit_transform(data['gene_type'])\n",
    "\n",
    "# Define features and target\n",
    "X = data[['unstranded', 'stranded_first', 'stranded_second', \n",
    "          'tpm_unstranded', 'fpkm_unstranded', 'fpkm_uq_unstranded']]\n",
    "y = data['label']\n",
    "\n",
    "# Impute missing values in X\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "    max_depth = trial.suggest_int('max_depth', 5, 30)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
    "\n",
    "    # Train the Random Forest Classifier\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Return the accuracy score\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Run the optimization\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Train the final model with the best parameters\n",
    "final_model = RandomForestClassifier(**best_params, random_state=42)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "# Evaluate the final model\n",
    "print(\"Final Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Final Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745794ae-651d-4a72-b1c8-a72bd36fdab4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
